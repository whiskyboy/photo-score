{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model define\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, GlobalMaxPool2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential([\n",
    "    GlobalAveragePooling2D(input_shape=(2048, 8, 8)),\n",
    "    Dense(1024, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='tanh')\n",
    "    ])\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare img scores\n",
    "img2score = {}\n",
    "with open(\"./data/img_score.csv\", 'r') as fin:\n",
    "    for line in fin:\n",
    "        imgid, score = line.strip().split(\"\\t\")\n",
    "        img2score[int(imgid)] = float(score)\n",
    "        \n",
    "        if img2score[int(imgid)] > 5:\n",
    "            img2score[int(imgid)] = 5\n",
    "        if img2score[int(imgid)] < -5:\n",
    "            img2score[int(imgid)] = -5\n",
    "        img2score[int(imgid)] = img2score[int(imgid)] / 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading npzfile: imgs_epoch=5.npz of pass=0\n",
      "Train on 4894 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4894/4894 [==============================] - 1s - loss: 0.9099 - mean_absolute_error: 0.9138 - val_loss: 0.7953 - val_mean_absolute_error: 0.8342\n",
      "loading npzfile: imgs_epoch=11.npz of pass=0\n",
      "Train on 4906 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4906/4906 [==============================] - 1s - loss: 0.8078 - mean_absolute_error: 0.8417 - val_loss: 0.9308 - val_mean_absolute_error: 0.9242\n",
      "loading npzfile: imgs_epoch=4.npz of pass=0\n",
      "Train on 4905 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4905/4905 [==============================] - 1s - loss: 0.5685 - mean_absolute_error: 0.6744 - val_loss: 0.7101 - val_mean_absolute_error: 0.7904\n",
      "loading npzfile: imgs_epoch=10.npz of pass=0\n",
      "Train on 4910 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4910/4910 [==============================] - 1s - loss: 0.4040 - mean_absolute_error: 0.5447 - val_loss: 0.6621 - val_mean_absolute_error: 0.7337\n",
      "loading npzfile: imgs_epoch=6.npz of pass=0\n",
      "Train on 4907 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4907/4907 [==============================] - 1s - loss: 0.2856 - mean_absolute_error: 0.4448 - val_loss: 0.4210 - val_mean_absolute_error: 0.5525\n",
      "loading npzfile: imgs_epoch=19.npz of pass=0\n",
      "Train on 4920 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4920/4920 [==============================] - 1s - loss: 0.2164 - mean_absolute_error: 0.3745 - val_loss: 0.1952 - val_mean_absolute_error: 0.3407\n",
      "loading npzfile: imgs_epoch=20.npz of pass=0\n",
      "Train on 4888 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4888/4888 [==============================] - 1s - loss: 0.1714 - mean_absolute_error: 0.3273 - val_loss: 0.1687 - val_mean_absolute_error: 0.3351\n",
      "loading npzfile: imgs_epoch=7.npz of pass=0\n",
      "Train on 4885 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4885/4885 [==============================] - 1s - loss: 0.1411 - mean_absolute_error: 0.2919 - val_loss: 0.1389 - val_mean_absolute_error: 0.2918\n",
      "loading npzfile: imgs_epoch=12.npz of pass=0\n",
      "Train on 4903 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4903/4903 [==============================] - 1s - loss: 0.1142 - mean_absolute_error: 0.2599 - val_loss: 0.0642 - val_mean_absolute_error: 0.1946\n",
      "loading npzfile: imgs_epoch=16.npz of pass=0\n",
      "Train on 4894 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4894/4894 [==============================] - 1s - loss: 0.1010 - mean_absolute_error: 0.2419 - val_loss: 0.0776 - val_mean_absolute_error: 0.2127\n",
      "loading npzfile: imgs_epoch=15.npz of pass=0\n",
      "Train on 4888 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4888/4888 [==============================] - 1s - loss: 0.0782 - mean_absolute_error: 0.2121 - val_loss: 0.1108 - val_mean_absolute_error: 0.2615\n",
      "loading npzfile: imgs_epoch=8.npz of pass=0\n",
      "Train on 4887 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4887/4887 [==============================] - 1s - loss: 0.0733 - mean_absolute_error: 0.2038 - val_loss: 0.0555 - val_mean_absolute_error: 0.1834\n",
      "loading npzfile: imgs_epoch=14.npz of pass=0\n",
      "Train on 4906 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4906/4906 [==============================] - 1s - loss: 0.0638 - mean_absolute_error: 0.1904 - val_loss: 0.0604 - val_mean_absolute_error: 0.1899\n",
      "loading npzfile: imgs_epoch=24.npz of pass=0\n",
      "Train on 4899 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4899/4899 [==============================] - 1s - loss: 0.0584 - mean_absolute_error: 0.1818 - val_loss: 0.0403 - val_mean_absolute_error: 0.1509\n",
      "loading npzfile: imgs_epoch=22.npz of pass=0\n",
      "Train on 4890 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4890/4890 [==============================] - 1s - loss: 0.0580 - mean_absolute_error: 0.1812 - val_loss: 0.0486 - val_mean_absolute_error: 0.1642\n",
      "loading npzfile: imgs_epoch=1.npz of pass=0\n",
      "Train on 4900 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4900/4900 [==============================] - 1s - loss: 0.0530 - mean_absolute_error: 0.1736 - val_loss: 0.0545 - val_mean_absolute_error: 0.1809\n",
      "loading npzfile: imgs_epoch=21.npz of pass=0\n",
      "Train on 4908 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4908/4908 [==============================] - 1s - loss: 0.0524 - mean_absolute_error: 0.1713 - val_loss: 0.0404 - val_mean_absolute_error: 0.1511\n",
      "loading npzfile: imgs_epoch=23.npz of pass=0\n",
      "Train on 4894 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4894/4894 [==============================] - 1s - loss: 0.0506 - mean_absolute_error: 0.1687 - val_loss: 0.0419 - val_mean_absolute_error: 0.1536\n",
      "loading npzfile: imgs_epoch=9.npz of pass=0\n",
      "Train on 4889 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4889/4889 [==============================] - 1s - loss: 0.0485 - mean_absolute_error: 0.1656 - val_loss: 0.0505 - val_mean_absolute_error: 0.1691\n",
      "loading npzfile: imgs_epoch=2.npz of pass=0\n",
      "Train on 4885 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4885/4885 [==============================] - 1s - loss: 0.0470 - mean_absolute_error: 0.1637 - val_loss: 0.0505 - val_mean_absolute_error: 0.1694\n",
      "loading npzfile: imgs_epoch=0.npz of pass=0\n",
      "Train on 4877 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4877/4877 [==============================] - 1s - loss: 0.0449 - mean_absolute_error: 0.1606 - val_loss: 0.0508 - val_mean_absolute_error: 0.1702\n",
      "loading npzfile: imgs_epoch=17.npz of pass=0\n",
      "Train on 4887 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4887/4887 [==============================] - 1s - loss: 0.0446 - mean_absolute_error: 0.1592 - val_loss: 0.0439 - val_mean_absolute_error: 0.1584\n",
      "loading npzfile: imgs_epoch=18.npz of pass=0\n",
      "Train on 4908 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4908/4908 [==============================] - 1s - loss: 0.0433 - mean_absolute_error: 0.1560 - val_loss: 0.0412 - val_mean_absolute_error: 0.1530\n",
      "loading npzfile: imgs_epoch=13.npz of pass=0\n",
      "Train on 4874 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4874/4874 [==============================] - 1s - loss: 0.0400 - mean_absolute_error: 0.1524 - val_loss: 0.0397 - val_mean_absolute_error: 0.1507\n",
      "loading npzfile: imgs_epoch=3.npz of pass=0\n",
      "Train on 4902 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4902/4902 [==============================] - 1s - loss: 0.0407 - mean_absolute_error: 0.1514 - val_loss: 0.0438 - val_mean_absolute_error: 0.1600\n",
      "loading npzfile: imgs_epoch=17.npz of pass=1\n",
      "Train on 4887 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4887/4887 [==============================] - 1s - loss: 0.0413 - mean_absolute_error: 0.1527 - val_loss: 0.0509 - val_mean_absolute_error: 0.1693\n",
      "loading npzfile: imgs_epoch=21.npz of pass=1\n",
      "Train on 4908 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4908/4908 [==============================] - 1s - loss: 0.0404 - mean_absolute_error: 0.1514 - val_loss: 0.0413 - val_mean_absolute_error: 0.1548\n",
      "loading npzfile: imgs_epoch=7.npz of pass=1\n",
      "Train on 4885 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4885/4885 [==============================] - 1s - loss: 0.0400 - mean_absolute_error: 0.1510 - val_loss: 0.0442 - val_mean_absolute_error: 0.1567\n",
      "loading npzfile: imgs_epoch=19.npz of pass=1\n",
      "Train on 4920 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4920/4920 [==============================] - 1s - loss: 0.0415 - mean_absolute_error: 0.1522 - val_loss: 0.0386 - val_mean_absolute_error: 0.1482\n",
      "loading npzfile: imgs_epoch=3.npz of pass=1\n",
      "Train on 4902 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4902/4902 [==============================] - 1s - loss: 0.0384 - mean_absolute_error: 0.1475 - val_loss: 0.0387 - val_mean_absolute_error: 0.1506\n",
      "loading npzfile: imgs_epoch=10.npz of pass=1\n",
      "Train on 4910 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4910/4910 [==============================] - 1s - loss: 0.0395 - mean_absolute_error: 0.1490 - val_loss: 0.0387 - val_mean_absolute_error: 0.1508\n",
      "loading npzfile: imgs_epoch=18.npz of pass=1\n",
      "Train on 4908 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4908/4908 [==============================] - 1s - loss: 0.0398 - mean_absolute_error: 0.1495 - val_loss: 0.0382 - val_mean_absolute_error: 0.1486\n",
      "loading npzfile: imgs_epoch=16.npz of pass=1\n",
      "Train on 4894 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4894/4894 [==============================] - 1s - loss: 0.0406 - mean_absolute_error: 0.1491 - val_loss: 0.0390 - val_mean_absolute_error: 0.1499\n",
      "loading npzfile: imgs_epoch=6.npz of pass=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4907 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4907/4907 [==============================] - 1s - loss: 0.0399 - mean_absolute_error: 0.1486 - val_loss: 0.0419 - val_mean_absolute_error: 0.1508\n",
      "loading npzfile: imgs_epoch=24.npz of pass=1\n",
      "Train on 4899 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4899/4899 [==============================] - 1s - loss: 0.0378 - mean_absolute_error: 0.1458 - val_loss: 0.0402 - val_mean_absolute_error: 0.1506\n",
      "loading npzfile: imgs_epoch=0.npz of pass=1\n",
      "Train on 4877 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4877/4877 [==============================] - 1s - loss: 0.0384 - mean_absolute_error: 0.1470 - val_loss: 0.0387 - val_mean_absolute_error: 0.1498\n",
      "loading npzfile: imgs_epoch=13.npz of pass=1\n",
      "Train on 4874 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4874/4874 [==============================] - 1s - loss: 0.0360 - mean_absolute_error: 0.1444 - val_loss: 0.0400 - val_mean_absolute_error: 0.1545\n",
      "loading npzfile: imgs_epoch=22.npz of pass=1\n",
      "Train on 4890 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4890/4890 [==============================] - 1s - loss: 0.0394 - mean_absolute_error: 0.1479 - val_loss: 0.0384 - val_mean_absolute_error: 0.1489\n",
      "loading npzfile: imgs_epoch=20.npz of pass=1\n",
      "Train on 4888 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4888/4888 [==============================] - 1s - loss: 0.0373 - mean_absolute_error: 0.1450 - val_loss: 0.0383 - val_mean_absolute_error: 0.1481\n",
      "loading npzfile: imgs_epoch=15.npz of pass=1\n",
      "Train on 4888 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4888/4888 [==============================] - 1s - loss: 0.0378 - mean_absolute_error: 0.1446 - val_loss: 0.0382 - val_mean_absolute_error: 0.1483\n",
      "loading npzfile: imgs_epoch=9.npz of pass=1\n",
      "Train on 4889 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4889/4889 [==============================] - 1s - loss: 0.0381 - mean_absolute_error: 0.1464 - val_loss: 0.0400 - val_mean_absolute_error: 0.1526\n",
      "loading npzfile: imgs_epoch=14.npz of pass=1\n",
      "Train on 4906 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4906/4906 [==============================] - 1s - loss: 0.0375 - mean_absolute_error: 0.1446 - val_loss: 0.0382 - val_mean_absolute_error: 0.1471\n",
      "loading npzfile: imgs_epoch=5.npz of pass=1\n",
      "Train on 4894 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4894/4894 [==============================] - 1s - loss: 0.0381 - mean_absolute_error: 0.1465 - val_loss: 0.0380 - val_mean_absolute_error: 0.1478\n",
      "loading npzfile: imgs_epoch=1.npz of pass=1\n",
      "Train on 4900 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4900/4900 [==============================] - 1s - loss: 0.0374 - mean_absolute_error: 0.1444 - val_loss: 0.0395 - val_mean_absolute_error: 0.1490\n",
      "loading npzfile: imgs_epoch=2.npz of pass=1\n",
      "Train on 4885 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4885/4885 [==============================] - 1s - loss: 0.0393 - mean_absolute_error: 0.1481 - val_loss: 0.0398 - val_mean_absolute_error: 0.1493\n",
      "loading npzfile: imgs_epoch=4.npz of pass=1\n",
      "Train on 4905 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4905/4905 [==============================] - 1s - loss: 0.0356 - mean_absolute_error: 0.1407 - val_loss: 0.0378 - val_mean_absolute_error: 0.1475\n",
      "loading npzfile: imgs_epoch=11.npz of pass=1\n",
      "Train on 4906 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4906/4906 [==============================] - 1s - loss: 0.0390 - mean_absolute_error: 0.1481 - val_loss: 0.0376 - val_mean_absolute_error: 0.1475\n",
      "loading npzfile: imgs_epoch=8.npz of pass=1\n",
      "Train on 4887 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4887/4887 [==============================] - 1s - loss: 0.0374 - mean_absolute_error: 0.1443 - val_loss: 0.0391 - val_mean_absolute_error: 0.1538\n",
      "loading npzfile: imgs_epoch=12.npz of pass=1\n",
      "Train on 4903 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4903/4903 [==============================] - 1s - loss: 0.0375 - mean_absolute_error: 0.1441 - val_loss: 0.0404 - val_mean_absolute_error: 0.1507\n",
      "loading npzfile: imgs_epoch=23.npz of pass=1\n",
      "Train on 4894 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4894/4894 [==============================] - 1s - loss: 0.0375 - mean_absolute_error: 0.1453 - val_loss: 0.0381 - val_mean_absolute_error: 0.1470\n",
      "loading npzfile: imgs_epoch=18.npz of pass=2\n",
      "Train on 4908 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "4908/4908 [==============================] - 1s - loss: 0.0376 - mean_absolute_error: 0.1436 - val_loss: 0.0380 - val_mean_absolute_error: 0.1500\n",
      "loading npzfile: imgs_epoch=22.npz of pass=2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-200a9a8f77e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"loading npzfile: %s of pass=%d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpzfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecompressNPZ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpzfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-200a9a8f77e2>\u001b[0m in \u001b[0;36mdecompressNPZ\u001b[0;34m(npzfile)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnpz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnpzfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimg_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnpz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mimg_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnpz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mimgid\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mimg_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    232\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m                     \u001b[0mread_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_read_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                     \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m                     array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[1;32m    675\u001b[0m                                                              count=read_count)\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;31m# done about that.  note that regular files can't be non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/zipfile.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/zipfile.pyc\u001b[0m in \u001b[0;36mread1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    682\u001b[0m             data = self._decompressor.decompress(\n\u001b[1;32m    683\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unconsumed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m                 \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_readbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_READ_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m             )\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load train and valid data\n",
    "import os\n",
    "import random\n",
    "\n",
    "feature_path = \"../data/pretrained_features/\"\n",
    "npzfile_list = os.listdir(feature_path)\n",
    "\n",
    "def decompressNPZ(npzfile):\n",
    "    ids = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    npz = np.load(feature_path+npzfile)\n",
    "    img_ids = npz['img_ids']\n",
    "    img_features = npz['img_features']\n",
    "    for _ in range(len(img_ids)):\n",
    "        imgid= img_ids[_]\n",
    "        feature = img_features[_]\n",
    "        if imgid in img2score:\n",
    "            ids.append(imgid)\n",
    "            X.append(feature)\n",
    "            Y.append(img2score[imgid])\n",
    "\n",
    "    return ids, np.array(X), np.array(Y)\n",
    "        \n",
    "\n",
    "imgid_valid, X_valid, Y_valid = decompressNPZ(\"imgs_epoch=25.npz\")\n",
    "\n",
    "for _pass in range(10):\n",
    "    random.shuffle(npzfile_list)\n",
    "    for npzfile in npzfile_list:\n",
    "        if npzfile == \"imgs_epoch=25.npz\":\n",
    "                continue\n",
    "        print \"loading npzfile: %s of pass=%d\"%(npzfile, _pass)\n",
    "\n",
    "        _, X_train, Y_train = decompressNPZ(npzfile)\n",
    "\n",
    "        model.fit(X_train, Y_train, batch_size=64, epochs=1, validation_data=(X_valid, Y_valid), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.13345201]\n",
      " [ 0.13345201  1.        ]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f48ad726534b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "Y_predict = model.predict(X_valid)\n",
    "#for _ in range(len(Y_valid)):\n",
    "#    print Y_valid[_], Y_predict[_, 0]\n",
    "\n",
    "data = np.array([Y_valid, Y_predict.reshape((len(Y_predict), ))])\n",
    "print np.corrcoef(data)\n",
    "\n",
    "plt.plot(Y_valid, Y_predict[:,0], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(imgid, title=\"\"):\n",
    "    if type(imgid) != str:\n",
    "        imgid = str(int(imgid))\n",
    "    img_file = \"../data/img/%s.jpg\"%imgid\n",
    "    img = Image.open(img_file)\n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "img_ids, img_features, img_scores = decompressNPZ(\"imgs_epoch=25.npz\")\n",
    "img_predicts = model.predict(img_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = img_predicts.reshape((len(img_predicts),)).argsort(axis=0)\n",
    "sort_idx = img_scores.argsort(axis=0)\n",
    "\n",
    "for idx in sort_idx[-10:]:\n",
    "    plot(img_ids[idx], \"%s: %s vs %s\"%(img_ids[idx], img_predicts[idx, 0], img_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(img_scores, 100)\n",
    "plt.show()\n",
    "\n",
    "np.corrcoef(img_scores, img_predicts[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"./layer3_bn_do0.5_tanh.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
