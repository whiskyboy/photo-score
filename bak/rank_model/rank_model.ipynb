{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "img_feature_a = Input(shape=(2048,))\n",
    "img_feature_b = Input(shape=(2048,))\n",
    "\n",
    "shared_fc_layer = Sequential([\n",
    "    Dense(1024, activation='sigmoid', input_shape=(2048, )),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, activation='sigmoid'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "])\n",
    "\n",
    "encoded_a = shared_fc_layer(img_feature_a)\n",
    "encoded_b = shared_fc_layer(img_feature_b)\n",
    "\n",
    "merged_vector = concatenate([encoded_a, encoded_b])\n",
    "\n",
    "x = Dense(1024, activation='sigmoid')(merged_vector)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[img_feature_a, img_feature_b], outputs=output)\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pklfile: 201702.pkl of pass=0\n",
      "Train on 62962 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "62962/62962 [==============================] - 7s - loss: 0.6306 - acc: 0.7350 - val_loss: 1.3952 - val_acc: 0.5154\n",
      "loading pklfile: 201701.pkl of pass=0\n",
      "Train on 48047 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "48047/48047 [==============================] - 5s - loss: 0.3478 - acc: 0.8317 - val_loss: 1.9579 - val_acc: 0.5132\n",
      "loading pklfile: 201703.pkl of pass=0\n",
      "Train on 69487 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "69487/69487 [==============================] - 7s - loss: 0.3355 - acc: 0.8390 - val_loss: 1.7418 - val_acc: 0.5491\n",
      "loading pklfile: 201701.pkl of pass=1\n",
      "Train on 48047 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "48047/48047 [==============================] - 5s - loss: 0.1440 - acc: 0.9437 - val_loss: 2.1560 - val_acc: 0.5275\n",
      "loading pklfile: 201703.pkl of pass=1\n",
      "Train on 69487 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "69487/69487 [==============================] - 7s - loss: 0.1146 - acc: 0.9570 - val_loss: 2.0613 - val_acc: 0.5525\n",
      "loading pklfile: 201702.pkl of pass=1\n",
      "Train on 62962 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "62962/62962 [==============================] - 7s - loss: 0.2368 - acc: 0.8980 - val_loss: 2.0390 - val_acc: 0.5098\n",
      "loading pklfile: 201701.pkl of pass=2\n",
      "Train on 48047 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "48047/48047 [==============================] - 5s - loss: 0.1125 - acc: 0.9577 - val_loss: 1.7982 - val_acc: 0.5433\n",
      "loading pklfile: 201702.pkl of pass=2\n",
      "Train on 62962 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "62962/62962 [==============================] - 7s - loss: 0.1068 - acc: 0.9604 - val_loss: 2.2347 - val_acc: 0.5443\n",
      "loading pklfile: 201703.pkl of pass=2\n",
      "Train on 69487 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "69487/69487 [==============================] - 8s - loss: 0.1036 - acc: 0.9616 - val_loss: 2.0421 - val_acc: 0.5494\n",
      "loading pklfile: 201701.pkl of pass=3\n",
      "Train on 48047 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "48047/48047 [==============================] - 5s - loss: 0.0890 - acc: 0.9681 - val_loss: 2.2245 - val_acc: 0.5079\n",
      "loading pklfile: 201703.pkl of pass=3\n",
      "Train on 69487 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "69487/69487 [==============================] - 7s - loss: 0.0673 - acc: 0.9763 - val_loss: 2.2145 - val_acc: 0.5426\n",
      "loading pklfile: 201702.pkl of pass=3\n",
      "Train on 62962 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "62962/62962 [==============================] - 7s - loss: 0.1046 - acc: 0.9606 - val_loss: 2.1365 - val_acc: 0.5270\n",
      "loading pklfile: 201702.pkl of pass=4\n",
      "Train on 62962 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "62962/62962 [==============================] - 7s - loss: 0.0592 - acc: 0.9787 - val_loss: 2.2877 - val_acc: 0.5321\n",
      "loading pklfile: 201703.pkl of pass=4\n",
      "Train on 69487 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "69487/69487 [==============================] - 7s - loss: 0.0694 - acc: 0.9758 - val_loss: 2.4876 - val_acc: 0.5294\n",
      "loading pklfile: 201701.pkl of pass=4\n",
      "Train on 48047 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "48047/48047 [==============================] - 5s - loss: 0.0919 - acc: 0.9679 - val_loss: 2.1211 - val_acc: 0.5350\n",
      "loading pklfile: 201703.pkl of pass=5\n",
      "Train on 69487 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "69487/69487 [==============================] - 7s - loss: 0.0515 - acc: 0.9817 - val_loss: 2.2264 - val_acc: 0.5523\n",
      "loading pklfile: 201702.pkl of pass=5\n",
      "Train on 62962 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "62962/62962 [==============================] - 7s - loss: 0.0792 - acc: 0.9721 - val_loss: 2.0548 - val_acc: 0.5296\n",
      "loading pklfile: 201701.pkl of pass=5\n",
      "Train on 48047 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "48047/48047 [==============================] - 5s - loss: 0.0783 - acc: 0.9720 - val_loss: 1.8132 - val_acc: 0.5442\n",
      "loading pklfile: 201703.pkl of pass=6\n",
      "Train on 69487 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "69487/69487 [==============================] - 8s - loss: 0.0511 - acc: 0.9820 - val_loss: 2.3338 - val_acc: 0.5462\n",
      "loading pklfile: 201701.pkl of pass=6\n",
      "Train on 48047 samples, validate on 18399 samples\n",
      "Epoch 1/1\n",
      "38528/48047 [=======================>......] - ETA: 1s - loss: 0.0652 - acc: 0.9775"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-78af8e0dfd6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         model.fit([X_1, X_2], Y, batch_size=batch_size, epochs=1, \n\u001b[0;32m---> 33\u001b[0;31m                   validation_data=([X_1_valid, X_2_valid], Y_valid), shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/theano/ifelse.pyc\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "def load_dataset(pklfile):\n",
    "    pair_samples = pickle.load(open(pklfile, 'rb'))\n",
    "    X_1 = np.array(map(lambda x: x[2], pair_samples))\n",
    "    X_2 = np.array(map(lambda x: x[3], pair_samples))\n",
    "    Y = np.array(map(lambda x: x[4], pair_samples))\n",
    "    Y[Y==-1] = 0\n",
    "    return X_1, X_2, Y\n",
    "\n",
    "X_1_valid, X_2_valid, Y_valid = load_dataset(\"./data/201704.pkl\")\n",
    "Y_valid = to_categorical(Y_valid, num_classes=2)\n",
    "\n",
    "batch_size = 128\n",
    "pklfile_list = os.listdir(\"./data/\")\n",
    "\n",
    "for _pass in range(10):\n",
    "    random.shuffle(pklfile_list)\n",
    "    for pklfile in pklfile_list:\n",
    "        #if pklfile < \"2017\":\n",
    "        #    continue\n",
    "        if pklfile == \"201704.pkl\":\n",
    "            continue\n",
    "        print \"loading pklfile: %s of pass=%d\"%(pklfile, _pass)\n",
    "        \n",
    "        X_1, X_2, Y = load_dataset(\"./data/\"+pklfile)\n",
    "        Y = to_categorical(Y, num_classes=2)\n",
    "\n",
    "        model.fit([X_1, X_2], Y, batch_size=batch_size, epochs=1, \n",
    "                  validation_data=([X_1_valid, X_2_valid], Y_valid), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 930400 samples, validate on 20418 samples\n",
      "Epoch 1/10\n",
      "930400/930400 [==============================] - 393s - loss: 0.5464 - acc: 0.7202 - val_loss: 0.8311 - val_acc: 0.6029\n",
      "Epoch 2/10\n",
      "930400/930400 [==============================] - 163s - loss: 0.3172 - acc: 0.8610 - val_loss: 0.9827 - val_acc: 0.6085\n",
      "Epoch 3/10\n",
      "930400/930400 [==============================] - 102s - loss: 0.2426 - acc: 0.8976 - val_loss: 1.1392 - val_acc: 0.5994\n",
      "Epoch 4/10\n",
      "930400/930400 [==============================] - 99s - loss: 0.2089 - acc: 0.9134 - val_loss: 1.1105 - val_acc: 0.6203\n",
      "Epoch 5/10\n",
      "930400/930400 [==============================] - 99s - loss: 0.1873 - acc: 0.9232 - val_loss: 1.1599 - val_acc: 0.6239\n",
      "Epoch 6/10\n",
      "930400/930400 [==============================] - 99s - loss: 0.1727 - acc: 0.9295 - val_loss: 1.2715 - val_acc: 0.6000\n",
      "Epoch 7/10\n",
      "930400/930400 [==============================] - 99s - loss: 0.1636 - acc: 0.9336 - val_loss: 1.2072 - val_acc: 0.6242\n",
      "Epoch 8/10\n",
      "930400/930400 [==============================] - 99s - loss: 0.1563 - acc: 0.9368 - val_loss: 1.2976 - val_acc: 0.6119\n",
      "Epoch 9/10\n",
      "102528/930400 [==>...........................] - ETA: 88s - loss: 0.1483 - acc: 0.9396"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a2b9f1d16766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m model.fit([X_1, X_2], Y, batch_size=batch_size, epochs=10, \n\u001b[0;32m---> 22\u001b[0;31m             validation_data=([X_1_valid, X_2_valid], Y_valid), shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "def load_dataset(pklfile):\n",
    "    pair_samples = pickle.load(open(pklfile, 'rb'))\n",
    "    X_1 = np.array(map(lambda x: x[2], pair_samples))\n",
    "    X_2 = np.array(map(lambda x: x[3], pair_samples))\n",
    "    Y = np.array(map(lambda x: x[4], pair_samples))\n",
    "    Y[Y==-1] = 0\n",
    "    return X_1, X_2, Y\n",
    "\n",
    "X_1, X_2, Y = load_dataset(\"./data/sybj.pkl\")\n",
    "Y = to_categorical(Y, num_classes=2)\n",
    "X_1_valid, X_2_valid, Y_valid = load_dataset(\"./data/sybj.valid.pkl\")\n",
    "Y_valid = to_categorical(Y_valid, num_classes=2)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "model.fit([X_1, X_2], Y, batch_size=batch_size, epochs=10, \n",
    "            validation_data=([X_1_valid, X_2_valid], Y_valid), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print X_1_valid.shape\n",
    "print X_2_valid.shape\n",
    "print Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_1_valid, X_2_valid, Y_valid = load_dataset(\"./data/201704.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_predict = model.predict([X_1_valid, X_2_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.17752544],\n",
       "       [ 0.17752544,  1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(Y_valid[:,1], Y_predict[:,1], 'bo')\n",
    "np.corrcoef([Y_valid[:], Y_predict[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
